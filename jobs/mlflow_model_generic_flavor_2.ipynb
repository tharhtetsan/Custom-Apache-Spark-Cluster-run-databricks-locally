{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF tensor input model flavors with MLflow Generic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version : 2.17.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import time\n",
    "import json\n",
    "from mlflow.models import infer_signature\n",
    "print(\"TF Version :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/907121710094613815', creation_time=1730914281381, experiment_id='907121710094613815', last_update_time=1730914281381, lifecycle_stage='active', name='test_new', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_uri = \"http://mlflow-server:8888\"\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "time.sleep(5)\n",
    "#mlflow.set_experiment(mlflow_uri)\n",
    "mlflow.set_experiment(\"test_new\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train) , (x_test,y_test) = mnist.load_data()\n",
    "x_train,x_test =  x_train/255.0 , x_test/255.0\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xffff0ca11cd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class custom_tf_model(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,params):\n",
    "        self.params = params\n",
    "        self.tf_model = None\n",
    "        self.config = None\n",
    "\n",
    "    def load_context(self, context = None, config_path = None):\n",
    "        if context:\n",
    "            config_path = context.artifacts[\"config_path\"]\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        self.config = json.load(open(config_path))\n",
    "\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        tf_model,eval_loss,eval_acc = self.train_model()\n",
    "        self.tf_model = tf_model\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        return self.tf_model.predict(model_input)\n",
    "    \n",
    "\n",
    "    def train_model(self,p_epoch=2, p_optimizer = \"Adam\", l1_noNode= 32, l1_activation=\"relu\",l1_dropout= 0.2):\n",
    "        loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(l1_noNode,activation=l1_activation),\n",
    "            tf.keras.layers.Dropout(l1_dropout),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "        model.compile(optimizer = p_optimizer,loss= loss_func, metrics = ['accuracy'])\n",
    "\n",
    "        model.fit(x_train,y_train,epochs = p_epoch)\n",
    "\n",
    "        eval_loss, eval_acc = model.evaluate(x_test,y_test,verbose=2)\n",
    "\n",
    "\n",
    "        print(f\"eval_loss : {eval_loss} | eval_acc : {eval_acc}\")\n",
    "\n",
    "        return model,eval_loss,eval_acc\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - accuracy: 0.7819 - loss: 0.7169\n",
      "Epoch 2/2\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 423us/step - accuracy: 0.9148 - loss: 0.2907\n",
      "313/313 - 0s - 413us/step - accuracy: 0.9516 - loss: 0.1685\n",
      "eval_loss : 0.16848136484622955 | eval_acc : 0.9516000151634216\n"
     ]
    }
   ],
   "source": [
    "config_path = \"data_tf.json\"\n",
    "params_ = {\n",
    "    \"epochs\" : 5\n",
    "}\n",
    "custom_tf_obj = custom_tf_model(params_)\n",
    "custom_tf_obj.load_context(config_path=config_path)\n",
    "custom_tf_obj.fit(x_train=x_train,y_train=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channels': ['defaults'],\n",
       " 'dependencies': ['python=3.12.7',\n",
       "  'pip',\n",
       "  {'pip': ['mlflow', 'tensorflow==2.17.0']}],\n",
       " 'name': 'tf_env'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import version_info\n",
    "conda_env_tf = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        f\"python={version_info.major}.{version_info.minor}.{version_info.micro}\",\n",
    "        \"pip\",\n",
    "        {\"pip\": [\"mlflow\",\n",
    "                 f\"tensorflow=={tf.__version__}\"]\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"tf_env\"\n",
    "}\n",
    "conda_env_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "predictions_tf = custom_tf_obj.predict(context=None,model_input=x_test)\n",
    "print(predictions_tf.shape)\n",
    "model_signature = infer_signature(x_test,predictions_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inputs: \n",
       "  [Tensor('float64', (-1, 28, 28))]\n",
       "outputs: \n",
       "  [Tensor('float32', (-1, 10))]\n",
       "params: \n",
       "  None"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model_signature)\n",
    "model_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'config_path': 'data_tf.json'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts_tf = {\n",
    "    \"config_path\" : config_path\n",
    "}\n",
    "artifacts_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/06 18:29:04 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "/usr/local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 1/1 [00:00<00:00, 3480.75it/s] \n",
      "Downloading artifacts: 100%|██████████| 8/8 [00:01<00:00,  5.39it/s]   \n",
      "2024/11/06 18:29:07 WARNING mlflow.models.model: Failed to validate serving input example {\n",
      "  \"inputs\": [\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.011764705882352941,\n",
      "      0.07058823529411765,\n",
      "      0.07058823529411765,\n",
      "      0.07058823529411765,\n",
      "      0.49411764705882355,\n",
      "      0.5333333333333333,\n",
      "      0.6862745098039216,\n",
      "      0.10196078431372549,\n",
      "      0.6509803921568628,\n",
      "      1.0,\n",
      "      0.9686274509803922,\n",
      "      0.4980392156862745,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.11764705882352941,\n",
      "      0.1411764705882353,\n",
      "      0.3686274509803922,\n",
      "      0.6039215686274509,\n",
      "      0.6666666666666666,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.8823529411764706,\n",
      "      0.6745098039215687,\n",
      "      0.9921568627450981,\n",
      "      0.9490196078431372,\n",
      "      0.7647058823529411,\n",
      "      0.25098039215686274,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.19215686274509805,\n",
      "      0.9333333333333333,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.984313725490196,\n",
      "      0.36470588235294116,\n",
      "      0.3215686274509804,\n",
      "      0.3215686274509804,\n",
      "      0.2196078431372549,\n",
      "      0.15294117647058825,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.07058823529411765,\n",
      "      0.8588235294117647,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.7764705882352941,\n",
      "      0.7137254901960784,\n",
      "      0.9686274509803922,\n",
      "      0.9450980392156862,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.3137254901960784,\n",
      "      0.611764705882353,\n",
      "      0.4196078431372549,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.803921568627451,\n",
      "      0.043137254901960784,\n",
      "      0.0,\n",
      "      0.16862745098039217,\n",
      "      0.6039215686274509,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.054901960784313725,\n",
      "      0.00392156862745098,\n",
      "      0.6039215686274509,\n",
      "      0.9921568627450981,\n",
      "      0.35294117647058826,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.5450980392156862,\n",
      "      0.9921568627450981,\n",
      "      0.7450980392156863,\n",
      "      0.00784313725490196,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.043137254901960784,\n",
      "      0.7450980392156863,\n",
      "      0.9921568627450981,\n",
      "      0.27450980392156865,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.13725490196078433,\n",
      "      0.9450980392156862,\n",
      "      0.8823529411764706,\n",
      "      0.6274509803921569,\n",
      "      0.4235294117647059,\n",
      "      0.00392156862745098,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.3176470588235294,\n",
      "      0.9411764705882353,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.4666666666666667,\n",
      "      0.09803921568627451,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.17647058823529413,\n",
      "      0.7294117647058823,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.5882352941176471,\n",
      "      0.10588235294117647,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.06274509803921569,\n",
      "      0.36470588235294116,\n",
      "      0.9882352941176471,\n",
      "      0.9921568627450981,\n",
      "      0.7333333333333333,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.9764705882352941,\n",
      "      0.9921568627450981,\n",
      "      0.9764705882352941,\n",
      "      0.25098039215686274,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.1803921568627451,\n",
      "      0.5098039215686274,\n",
      "      0.7176470588235294,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.8117647058823529,\n",
      "      0.00784313725490196,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.15294117647058825,\n",
      "      0.5803921568627451,\n",
      "      0.8980392156862745,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9803921568627451,\n",
      "      0.7137254901960784,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.09411764705882353,\n",
      "      0.4470588235294118,\n",
      "      0.8666666666666667,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.788235294117647,\n",
      "      0.3058823529411765,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.09019607843137255,\n",
      "      0.25882352941176473,\n",
      "      0.8352941176470589,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.7764705882352941,\n",
      "      0.3176470588235294,\n",
      "      0.00784313725490196,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.07058823529411765,\n",
      "      0.6705882352941176,\n",
      "      0.8588235294117647,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.7647058823529411,\n",
      "      0.3137254901960784,\n",
      "      0.03529411764705882,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.21568627450980393,\n",
      "      0.6745098039215687,\n",
      "      0.8862745098039215,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9568627450980393,\n",
      "      0.5215686274509804,\n",
      "      0.043137254901960784,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.5333333333333333,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.9921568627450981,\n",
      "      0.8313725490196079,\n",
      "      0.5294117647058824,\n",
      "      0.5176470588235295,\n",
      "      0.06274509803921569,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ],\n",
      "    [\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0,\n",
      "      0.0\n",
      "    ]\n",
      "  ]\n",
      "}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\n",
      "Got error: Failed to enforce schema of data '[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01176471 0.07058824 0.07058824 0.07058824 0.49411765 0.53333333\n",
      "  0.68627451 0.10196078 0.65098039 1.         0.96862745 0.49803922\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.11764706 0.14117647 0.36862745 0.60392157\n",
      "  0.66666667 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
      "  0.88235294 0.6745098  0.99215686 0.94901961 0.76470588 0.25098039\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.19215686 0.93333333 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.98431373\n",
      "  0.36470588 0.32156863 0.32156863 0.21960784 0.15294118 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.99215686 0.77647059 0.71372549 0.96862745 0.94509804\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.31372549 0.61176471 0.41960784 0.99215686\n",
      "  0.99215686 0.80392157 0.04313725 0.         0.16862745 0.60392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05490196 0.00392157 0.60392157\n",
      "  0.99215686 0.35294118 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.54509804\n",
      "  0.99215686 0.74509804 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.04313725\n",
      "  0.74509804 0.99215686 0.2745098  0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.1372549  0.94509804 0.88235294 0.62745098 0.42352941 0.00392157\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.31764706 0.94117647 0.99215686 0.99215686 0.46666667\n",
      "  0.09803922 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.17647059 0.72941176 0.99215686 0.99215686\n",
      "  0.58823529 0.10588235 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0627451  0.36470588 0.98823529\n",
      "  0.99215686 0.73333333 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.97647059\n",
      "  0.99215686 0.97647059 0.25098039 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.18039216 0.50980392 0.71764706 0.99215686\n",
      "  0.99215686 0.81176471 0.00784314 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.15294118 0.58039216 0.89803922 0.99215686 0.99215686 0.99215686\n",
      "  0.98039216 0.71372549 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.09411765 0.44705882\n",
      "  0.86666667 0.99215686 0.99215686 0.99215686 0.99215686 0.78823529\n",
      "  0.30588235 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09019608 0.25882353 0.83529412 0.99215686\n",
      "  0.99215686 0.99215686 0.99215686 0.77647059 0.31764706 0.00784314\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.07058824 0.67058824 0.85882353 0.99215686 0.99215686 0.99215686\n",
      "  0.99215686 0.76470588 0.31372549 0.03529412 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.21568627 0.6745098\n",
      "  0.88627451 0.99215686 0.99215686 0.99215686 0.99215686 0.95686275\n",
      "  0.52156863 0.04313725 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.53333333 0.99215686\n",
      "  0.99215686 0.99215686 0.83137255 0.52941176 0.51764706 0.0627451\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]' with schema '[Tensor('float64', (-1, 28, 28))]'. Error: Shape of input (28, 28) does not match expected shape (-1, 28, 28).\n",
      "2024/11/06 18:29:07 INFO mlflow.tracking._tracking_service.client: 🏃 View run generic_model3 at: http://mlflow-server:8888/#/experiments/907121710094613815/runs/ffd4e453ce084ed1827f014bd2e45b9a.\n",
      "2024/11/06 18:29:07 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://mlflow-server:8888/#/experiments/907121710094613815.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"generic_model3\") as run2:\n",
    "    mlflow.pyfunc.log_model(\n",
    "        \"custom_tf\",\n",
    "        python_model = custom_tf_obj,\n",
    "        artifacts = artifacts_tf,\n",
    "        conda_env = conda_env_tf,\n",
    "        signature = model_signature,\n",
    "        input_example = x_train[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00,  9.58it/s]   \n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "logged_model = 'runs:/ffd4e453ce084ed1827f014bd2e45b9a/custom_tf'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "result = loaded_model.predict(x_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.4426537 ,  -3.06995   ,   0.2740355 ,   2.6607463 ,\n",
       "         -6.3128624 ,  -4.584505  , -10.84436   ,  10.368501  ,\n",
       "         -2.5545783 ,  -0.11114074],\n",
       "       [  0.46572363,  -4.5337477 ,   9.314175  ,   2.7545025 ,\n",
       "        -13.770365  ,  -0.02056783,   0.8810861 ,  -9.267005  ,\n",
       "          1.4868357 , -14.073222  ],\n",
       "       [ -5.9646482 ,   5.4954066 ,   0.04175703,  -1.2263393 ,\n",
       "         -3.6333065 ,  -2.9939466 ,  -2.4284549 ,   0.08449449,\n",
       "         -0.18725787,  -3.4375913 ],\n",
       "       [  9.61409   , -10.465796  ,  -1.49919   ,  -2.4098573 ,\n",
       "         -6.679862  ,   2.2902415 ,   0.59040356,  -0.28892523,\n",
       "         -2.884301  ,   0.3558315 ],\n",
       "       [ -3.2562015 ,  -6.6417375 ,  -1.0696703 ,  -3.5255597 ,\n",
       "          5.2593346 ,  -3.8275075 ,  -0.7683228 ,  -0.8596637 ,\n",
       "         -1.3757745 ,   2.1302857 ],\n",
       "       [ -7.4357805 ,   6.481259  ,  -0.45360005,  -1.2074666 ,\n",
       "         -4.7650337 ,  -4.4144344 ,  -4.7796364 ,   0.8320346 ,\n",
       "         -0.09582964,  -3.1041229 ],\n",
       "       [ -9.184504  ,  -5.906163  ,  -5.2440457 ,  -3.8977456 ,\n",
       "          6.622325  ,  -0.6253586 ,  -5.297417  ,  -0.5603999 ,\n",
       "          1.9473455 ,   3.2566886 ],\n",
       "       [ -7.5205984 ,  -0.81570995,  -2.966077  ,  -0.18926732,\n",
       "          1.6149197 ,  -2.679988  ,  -4.7066793 ,   1.0796492 ,\n",
       "          0.06013124,   4.0994024 ],\n",
       "       [ -1.8631821 ,  -5.456913  ,   0.53870404,  -6.2820206 ,\n",
       "         -0.5196165 ,   2.1968892 ,   6.556286  ,  -7.692522  ,\n",
       "         -0.6652309 ,  -3.227696  ],\n",
       "       [ -8.387875  ,  -8.010926  ,  -6.069569  ,  -3.0600905 ,\n",
       "          2.0030303 ,  -4.3486943 ,  -7.0088563 ,   3.0343816 ,\n",
       "          1.323985  ,   7.2500844 ]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

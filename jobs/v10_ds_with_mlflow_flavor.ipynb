{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distibuted Training With Hyperparameter tuning and Generic Model Flavors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version : 2.19.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import time\n",
    "import json\n",
    "from sys import version_info\n",
    "from mlflow.models import infer_signature\n",
    "print(\"TF Version :\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/06 13:58:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"ds_with_mlflow_flavor\").master(\"spark://spark-master:7077\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/791152268774684723', creation_time=1749216281462, experiment_id='791152268774684723', last_update_time=1749216281462, lifecycle_stage='active', name='ds_with_mlflow_flavor', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow_uri = \"http://mlflow-server:8888\"\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "time.sleep(5)\n",
    "#mlflow.set_experiment(mlflow_uri)\n",
    "mlflow.set_experiment(\"ds_with_mlflow_flavor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train) , (x_test,y_test) = mnist.load_data()\n",
    "x_train,x_test =  x_train/255.0 , x_test/255.0\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xfffef19cd190>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "from hyperopt import SparkTrials, Trials\n",
    "\n",
    "spark_trails = Trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channels': ['defaults'],\n",
       " 'dependencies': ['python=3.11.13',\n",
       "  'pip',\n",
       "  {'pip': ['mlflow', 'tensorflow==2.19.0']}],\n",
       " 'name': 'tf_env'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import version_info\n",
    "conda_env_tf = {\n",
    "    \"channels\": [\"defaults\"],\n",
    "    \"dependencies\": [\n",
    "        f\"python={version_info.major}.{version_info.minor}.{version_info.micro}\",\n",
    "        \"pip\",\n",
    "        {\"pip\": [\"mlflow\",\n",
    "                 f\"tensorflow=={tf.__version__}\"]\n",
    "        },\n",
    "    ],\n",
    "    \"name\": \"tf_env\"\n",
    "}\n",
    "conda_env_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "class custom_tf_model(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self,params):\n",
    "        self.params = params\n",
    "        self.tf_model = None\n",
    "        self.config = None\n",
    "\n",
    "    def load_context(self, context = None, config_path = None):\n",
    "        if context:\n",
    "            config_path = context.artifacts[\"config_path\"]\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "        self.config = json.load(open(config_path))\n",
    "\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "\n",
    "        tf_model = self.create_model(p_optimizer=self.config[\"optimizer\"],\n",
    "                                     l1_noNode=self.config[\"l1_noNode\"],\n",
    "                                     l1_activation = self.config[\"l1_activation\"],\n",
    "                                     l1_dropout = self.config[\"l1_dropout\"])\n",
    "\n",
    "        print(x_train.shape)\n",
    "        tf_model.fit(x_train,y_train,epochs = self.params[\"epochs\"])\n",
    "        self.tf_model = tf_model\n",
    "\n",
    "\n",
    "    def predict(self,context, model_input):\n",
    "        \n",
    "        return self.tf_model.predict(model_input)\n",
    "    \n",
    "    def evaluate(self,context,test_x,test_y):\n",
    "        eval_loss, eval_acc = self.tf_model.evaluate(x_test,y_test,verbose=2)\n",
    "        return eval_loss, eval_acc\n",
    "\n",
    "\n",
    "    def create_model(self,p_optimizer = \"Adam\", l1_noNode= 32, l1_activation=\"relu\",l1_dropout= 0.2):\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(l1_noNode,activation=l1_activation),\n",
    "            tf.keras.layers.Dropout(l1_dropout),\n",
    "            tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "\n",
    "        loss_func = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "        model.compile(optimizer = p_optimizer,loss= loss_func, metrics = ['accuracy'])\n",
    "\n",
    "        return model\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_hyperopt(params):\n",
    "    with mlflow.start_run(nested=True) as run1 :\n",
    "        p_epoch = params[\"epochs\"]\n",
    "        p_optimizer = params[\"optimizer\"]\n",
    "        l1_noNode = params[\"l1_noNode\"]\n",
    "        l1_activation = params[\"l1_activation\"]\n",
    "        l1_dropout  = params[\"l1_dropout\"]\n",
    "\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # create the configfile\n",
    "        config_path = \"data_tf.json\"\n",
    "        artifacts_tf = {\"config_path\" : config_path}   \n",
    "        with open(config_path,\"w\") as f:\n",
    "            json.dump(params,f)\n",
    "        \n",
    "        # create generic model\n",
    "        params_ = {\"epochs\" : 5}\n",
    "        config_path = \"data_tf.json\"\n",
    "        custom_tf_model_obj = custom_tf_model(params_)\n",
    "        custom_tf_model_obj.load_context(config_path=config_path)\n",
    "        custom_tf_model_obj.fit(x_train=x_train,y_train=y_train)\n",
    "\n",
    "        # Calculate LOSS and Acc\n",
    "        eval_loss, eval_acc = custom_tf_model_obj.evaluate(context=None,\n",
    "                                                           test_x=x_test,\n",
    "                                                           test_y=y_test)\n",
    "\n",
    "     \n",
    "        mlflow.log_metric(\"eval_loss\",eval_loss)\n",
    "        mlflow.log_metric(\"eval_acc\",eval_acc)\n",
    "\n",
    "\n",
    "        # Prepare to generic model\n",
    "        predictions_tf = custom_tf_model_obj.predict(context=None,model_input=x_test)\n",
    "        model_signature = infer_signature(x_test,predictions_tf)\n",
    "        mlflow.pyfunc.log_model(\n",
    "            \"custom_tf\",\n",
    "            python_model = custom_tf_model_obj,\n",
    "            artifacts = artifacts_tf,\n",
    "            conda_env = conda_env_tf,\n",
    "            signature = model_signature,\n",
    "            input_example = x_train[0:5]\n",
    "        )\n",
    "\n",
    "\n",
    "    return {\"loss\" : eval_loss, \"status\" : STATUS_OK, \"model\" : custom_tf_model_obj, \"eval_acc\":eval_acc, \"run_id\": run1.info.run_id  \n",
    "}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = [2,4,6,8]\n",
    "optimizer = [\"Adam\",\"SGD\",\"RMSprop\"]\n",
    "l1_noNode = [32,64,128]\n",
    "l1_activation = [\"relu\",\"tanh\",\"softmax\"]\n",
    "l1_dropout = [0.2,0.3,0.6]\n",
    "\n",
    "\n",
    "search_params_space = {\n",
    "    \"epochs\" : hp.choice(\"epochs\",epochs),\n",
    "    \"optimizer\" : hp.choice(\"optimizer\",optimizer),\n",
    "    \"l1_noNode\" : hp.choice(\"l1_noNode\",l1_noNode),\n",
    "    \"l1_activation\" : hp.choice(\"l1_activation\",l1_activation),\n",
    "    \"l1_dropout\" : hp.choice(\"l1_dropout\",l1_dropout)\n",
    "}\n",
    "\n",
    "algo = tpe.suggest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function hyperopt.tpe.suggest(new_ids, domain, trials, seed, prior_weight=1.0, n_startup_jobs=20, n_EI_candidates=24, gamma=0.25, verbose=True)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/06 13:59:40 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)                                      \n",
      "  0%|          | 0/3 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5                                            \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m8:15\u001b[0m 265ms/step - accuracy: 0.1250 - loss: 2.3017\n",
      "\u001b[1m  35/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.1615 - loss: 2.2961    \n",
      "\u001b[1m  72/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2143 - loss: 2.2875\n",
      "\u001b[1m 111/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2550 - loss: 2.2754\n",
      "\u001b[1m 146/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2760 - loss: 2.2637\n",
      "\u001b[1m 182/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.2908 - loss: 2.2516\n",
      "\u001b[1m 227/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3031 - loss: 2.2367\n",
      "\u001b[1m 272/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.3116 - loss: 2.2222\n",
      "\u001b[1m 316/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3176 - loss: 2.2084\n",
      "\u001b[1m 363/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3226 - loss: 2.1941\n",
      "\u001b[1m 409/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3265 - loss: 2.1806\n",
      "\u001b[1m 454/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3299 - loss: 2.1680\n",
      "\u001b[1m 498/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3327 - loss: 2.1561\n",
      "\u001b[1m 545/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3355 - loss: 2.1440\n",
      "\u001b[1m 592/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3382 - loss: 2.1322\n",
      "\u001b[1m 626/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3401 - loss: 2.1240\n",
      "\u001b[1m 671/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3425 - loss: 2.1136\n",
      "\u001b[1m 715/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3447 - loss: 2.1037\n",
      "\u001b[1m 759/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3467 - loss: 2.0942\n",
      "\u001b[1m 801/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3486 - loss: 2.0854\n",
      "\u001b[1m 842/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3504 - loss: 2.0771\n",
      "\u001b[1m 885/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3522 - loss: 2.0687\n",
      "\u001b[1m 927/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3539 - loss: 2.0607\n",
      "\u001b[1m 970/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3555 - loss: 2.0528\n",
      "\u001b[1m1013/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.3571 - loss: 2.0450\n",
      "\u001b[1m1057/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3587 - loss: 2.0372\n",
      "\u001b[1m1097/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3601 - loss: 2.0304\n",
      "\u001b[1m1136/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3613 - loss: 2.0240\n",
      "\u001b[1m1172/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3624 - loss: 2.0182\n",
      "\u001b[1m1197/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3632 - loss: 2.0142\n",
      "\u001b[1m1230/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3642 - loss: 2.0090\n",
      "\u001b[1m1267/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3652 - loss: 2.0034\n",
      "\u001b[1m1311/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3664 - loss: 1.9969\n",
      "\u001b[1m1355/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3676 - loss: 1.9905\n",
      "\u001b[1m1399/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3687 - loss: 1.9843\n",
      "\u001b[1m1443/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3698 - loss: 1.9783\n",
      "\u001b[1m1489/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3708 - loss: 1.9721\n",
      "\u001b[1m1535/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3719 - loss: 1.9661\n",
      "\u001b[1m1575/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3728 - loss: 1.9610\n",
      "\u001b[1m1621/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3738 - loss: 1.9554\n",
      "\u001b[1m1669/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3748 - loss: 1.9496\n",
      "\u001b[1m1718/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3758 - loss: 1.9438\n",
      "\u001b[1m1767/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3767 - loss: 1.9382\n",
      "\u001b[1m1816/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3776 - loss: 1.9328\n",
      "\u001b[1m1865/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.3785 - loss: 1.9275\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.3787 - loss: 1.9263\n",
      "\n",
      "Epoch 2/5                                            \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.4062 - loss: 1.4720\n",
      "\u001b[1m  44/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4416 - loss: 1.4946 \n",
      "\u001b[1m  90/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4421 - loss: 1.5112\n",
      "\u001b[1m 138/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4460 - loss: 1.5111\n",
      "\u001b[1m 186/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4485 - loss: 1.5082\n",
      "\u001b[1m 229/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4505 - loss: 1.5051\n",
      "\u001b[1m 271/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4520 - loss: 1.5028\n",
      "\u001b[1m 319/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4537 - loss: 1.4995\n",
      "\u001b[1m 368/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4555 - loss: 1.4962\n",
      "\u001b[1m 417/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4568 - loss: 1.4935\n",
      "\u001b[1m 466/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4580 - loss: 1.4907\n",
      "\u001b[1m 515/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4589 - loss: 1.4883\n",
      "\u001b[1m 564/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4596 - loss: 1.4860\n",
      "\u001b[1m 607/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4601 - loss: 1.4842\n",
      "\u001b[1m 654/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4607 - loss: 1.4822\n",
      "\u001b[1m 702/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4614 - loss: 1.4802\n",
      "\u001b[1m 750/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4620 - loss: 1.4784\n",
      "\u001b[1m 799/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4625 - loss: 1.4765\n",
      "\u001b[1m 847/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4632 - loss: 1.4746\n",
      "\u001b[1m 877/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4636 - loss: 1.4735\n",
      "\u001b[1m 916/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4641 - loss: 1.4720\n",
      "\u001b[1m 962/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4647 - loss: 1.4704\n",
      "\u001b[1m1009/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4653 - loss: 1.4689\n",
      "\u001b[1m1056/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4659 - loss: 1.4673\n",
      "\u001b[1m1104/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4665 - loss: 1.4658\n",
      "\u001b[1m1147/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4671 - loss: 1.4645\n",
      "\u001b[1m1196/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4677 - loss: 1.4629\n",
      "\u001b[1m1245/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4684 - loss: 1.4614\n",
      "\u001b[1m1294/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4691 - loss: 1.4599\n",
      "\u001b[1m1344/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4698 - loss: 1.4584\n",
      "\u001b[1m1393/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4704 - loss: 1.4569\n",
      "\u001b[1m1443/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4711 - loss: 1.4555\n",
      "\u001b[1m1492/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4718 - loss: 1.4541\n",
      "\u001b[1m1541/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4726 - loss: 1.4527\n",
      "\u001b[1m1582/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4732 - loss: 1.4515\n",
      "\u001b[1m1631/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4740 - loss: 1.4500\n",
      "\u001b[1m1680/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4748 - loss: 1.4485\n",
      "\u001b[1m1729/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4756 - loss: 1.4470\n",
      "\u001b[1m1777/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4764 - loss: 1.4455\n",
      "\u001b[1m1826/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4772 - loss: 1.4440\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.4780 - loss: 1.4426\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.4780 - loss: 1.4425\n",
      "\n",
      "Epoch 3/5                                            \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 16ms/step - accuracy: 0.5312 - loss: 1.2680\n",
      "\u001b[1m  46/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5601 - loss: 1.3202  \n",
      "\u001b[1m  87/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5593 - loss: 1.3098\n",
      "\u001b[1m 121/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5576 - loss: 1.3080\n",
      "\u001b[1m 165/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5591 - loss: 1.3014\n",
      "\u001b[1m 211/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5606 - loss: 1.2943\n",
      "\u001b[1m 256/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5618 - loss: 1.2885\n",
      "\u001b[1m 304/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5632 - loss: 1.2834\n",
      "\u001b[1m 353/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5638 - loss: 1.2806\n",
      "\u001b[1m 400/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5640 - loss: 1.2789\n",
      "\u001b[1m 439/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5643 - loss: 1.2776\n",
      "\u001b[1m 488/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5648 - loss: 1.2757\n",
      "\u001b[1m 537/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5651 - loss: 1.2740\n",
      "\u001b[1m 586/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5654 - loss: 1.2725\n",
      "\u001b[1m 635/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5657 - loss: 1.2712\n",
      "\u001b[1m 678/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5660 - loss: 1.2700\n",
      "\u001b[1m 724/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5662 - loss: 1.2688\n",
      "\u001b[1m 772/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5664 - loss: 1.2676\n",
      "\u001b[1m 821/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5666 - loss: 1.2665\n",
      "\u001b[1m 870/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5668 - loss: 1.2655\n",
      "\u001b[1m 919/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5669 - loss: 1.2645\n",
      "\u001b[1m 968/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5670 - loss: 1.2635\n",
      "\u001b[1m1017/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5672 - loss: 1.2624\n",
      "\u001b[1m1066/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5674 - loss: 1.2614\n",
      "\u001b[1m1114/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5676 - loss: 1.2604\n",
      "\u001b[1m1159/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5677 - loss: 1.2595\n",
      "\u001b[1m1208/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5679 - loss: 1.2585\n",
      "\u001b[1m1258/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5681 - loss: 1.2574\n",
      "\u001b[1m1307/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5683 - loss: 1.2564\n",
      "\u001b[1m1356/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5684 - loss: 1.2554\n",
      "\u001b[1m1403/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5686 - loss: 1.2544\n",
      "\u001b[1m1451/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5688 - loss: 1.2534\n",
      "\u001b[1m1500/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5690 - loss: 1.2523\n",
      "\u001b[1m1549/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5691 - loss: 1.2513\n",
      "\u001b[1m1598/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5693 - loss: 1.2504\n",
      "\u001b[1m1648/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5695 - loss: 1.2494\n",
      "\u001b[1m1692/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5697 - loss: 1.2485\n",
      "\u001b[1m1738/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5698 - loss: 1.2475\n",
      "\u001b[1m1787/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5700 - loss: 1.2466\n",
      "\u001b[1m1818/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5701 - loss: 1.2460\n",
      "\u001b[1m1858/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5703 - loss: 1.2452\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5703 - loss: 1.2449\n",
      "\n",
      "Epoch 4/5                                            \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.5625 - loss: 1.2673\n",
      "\u001b[1m  44/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5781 - loss: 1.1679  \n",
      "\u001b[1m  85/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5832 - loss: 1.1581\n",
      "\u001b[1m 132/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5845 - loss: 1.1560\n",
      "\u001b[1m 179/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5860 - loss: 1.1528\n",
      "\u001b[1m 223/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5863 - loss: 1.1524\n",
      "\u001b[1m 270/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5864 - loss: 1.1522\n",
      "\u001b[1m 318/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5863 - loss: 1.1515\n",
      "\u001b[1m 366/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5862 - loss: 1.1510\n",
      "\u001b[1m 412/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5861 - loss: 1.1506\n",
      "\u001b[1m 461/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5861 - loss: 1.1498\n",
      "\u001b[1m 510/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5863 - loss: 1.1489\n",
      "\u001b[1m 559/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5864 - loss: 1.1480\n",
      "\u001b[1m 608/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5865 - loss: 1.1471\n",
      "\u001b[1m 656/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5866 - loss: 1.1464\n",
      "\u001b[1m 699/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5866 - loss: 1.1458\n",
      "\u001b[1m 746/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5865 - loss: 1.1453\n",
      "\u001b[1m 795/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5865 - loss: 1.1447\n",
      "\u001b[1m 845/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5866 - loss: 1.1441\n",
      "\u001b[1m 893/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5866 - loss: 1.1436\n",
      "\u001b[1m 942/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5865 - loss: 1.1433\n",
      "\u001b[1m 992/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5865 - loss: 1.1429\n",
      "\u001b[1m1041/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5865 - loss: 1.1425\n",
      "\u001b[1m1090/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5866 - loss: 1.1420\n",
      "\u001b[1m1134/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5866 - loss: 1.1416\n",
      "\u001b[1m1182/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5867 - loss: 1.1412\n",
      "\u001b[1m1231/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5867 - loss: 1.1408\n",
      "\u001b[1m1280/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5868 - loss: 1.1404\n",
      "\u001b[1m1329/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5868 - loss: 1.1400\n",
      "\u001b[1m1378/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1396\n",
      "\u001b[1m1427/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1393\n",
      "\u001b[1m1476/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1389\n",
      "\u001b[1m1525/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1386\n",
      "\u001b[1m1574/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1383\n",
      "\u001b[1m1623/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1380\n",
      "\u001b[1m1672/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1377\n",
      "\u001b[1m1713/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5869 - loss: 1.1374\n",
      "\u001b[1m1761/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5870 - loss: 1.1371\n",
      "\u001b[1m1810/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5870 - loss: 1.1368\n",
      "\u001b[1m1859/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5870 - loss: 1.1365\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5870 - loss: 1.1364\n",
      "\n",
      "Epoch 5/5                                            \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6562 - loss: 1.0293\n",
      "\u001b[1m  46/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5890 - loss: 1.1165 \n",
      "\u001b[1m  75/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5887 - loss: 1.1087\n",
      "\u001b[1m 115/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5904 - loss: 1.0999\n",
      "\u001b[1m 161/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5921 - loss: 1.0941\n",
      "\u001b[1m 206/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5932 - loss: 1.0913\n",
      "\u001b[1m 249/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5941 - loss: 1.0894\n",
      "\u001b[1m 296/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5948 - loss: 1.0882\n",
      "\u001b[1m 346/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5952 - loss: 1.0878\n",
      "\u001b[1m 395/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 1.0874\n",
      "\u001b[1m 445/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5958 - loss: 1.0878\n",
      "\u001b[1m 494/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5957 - loss: 1.0883\n",
      "\u001b[1m 543/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 1.0887\n",
      "\u001b[1m 592/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5955 - loss: 1.0892\n",
      "\u001b[1m 642/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5955 - loss: 1.0897\n",
      "\u001b[1m 690/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5955 - loss: 1.0901\n",
      "\u001b[1m 730/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5956 - loss: 1.0903\n",
      "\u001b[1m 776/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5957 - loss: 1.0904\n",
      "\u001b[1m 824/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5960 - loss: 1.0903\n",
      "\u001b[1m 872/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5962 - loss: 1.0903\n",
      "\u001b[1m 921/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5964 - loss: 1.0904\n",
      "\u001b[1m 969/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5966 - loss: 1.0905\n",
      "\u001b[1m1018/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5968 - loss: 1.0906\n",
      "\u001b[1m1066/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5970 - loss: 1.0904\n",
      "\u001b[1m1115/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5973 - loss: 1.0903\n",
      "\u001b[1m1160/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5975 - loss: 1.0902\n",
      "\u001b[1m1209/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5978 - loss: 1.0901\n",
      "\u001b[1m1258/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5979 - loss: 1.0900\n",
      "\u001b[1m1308/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5982 - loss: 1.0899\n",
      "\u001b[1m1357/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5984 - loss: 1.0897\n",
      "\u001b[1m1407/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5986 - loss: 1.0894\n",
      "\u001b[1m1456/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5989 - loss: 1.0892\n",
      "\u001b[1m1505/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5992 - loss: 1.0890\n",
      "\u001b[1m1555/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5995 - loss: 1.0887\n",
      "\u001b[1m1604/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5998 - loss: 1.0884\n",
      "\u001b[1m1653/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6001 - loss: 1.0881\n",
      "\u001b[1m1702/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6004 - loss: 1.0878\n",
      "\u001b[1m1742/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6007 - loss: 1.0876\n",
      "\u001b[1m1788/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6010 - loss: 1.0873\n",
      "\u001b[1m1810/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6011 - loss: 1.0872\n",
      "\u001b[1m1855/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6014 - loss: 1.0870\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.6015 - loss: 1.0868\n",
      "\n",
      "313/313 - 0s - 629us/step - accuracy: 0.9277 - loss: 0.4685\n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step\n",
      "\u001b[1m131/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 385us/step\n",
      "\u001b[1m275/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 366us/step\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step\n",
      "\n",
      "  0%|          | 0/3 [00:11<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/06 13:59:52 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "\n",
      "/usr/local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|##########| 1/1 [00:00<00:00, 4415.06it/s]\n",
      "Downloading artifacts: 100%|##########| 1/1 [00:00<00:00, 1331.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      "🏃 View run legendary-crow-597 at: http://mlflow-server:8888/#/experiments/791152268774684723/runs/1371118d15974076abc73e71b0bd1236\n",
      "\n",
      "🧪 View experiment at: http://mlflow-server:8888/#/experiments/791152268774684723\n",
      "\n",
      "(60000, 28, 28)                                                                \n",
      " 33%|███▎      | 1/3 [00:12<00:25, 12.56s/trial, best loss: 0.4684818983078003]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:12\u001b[0m 199ms/step - accuracy: 0.0938 - loss: 2.3009\n",
      "\u001b[1m  70/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 729us/step - accuracy: 0.2218 - loss: 2.2795  \n",
      "\u001b[1m 148/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 684us/step - accuracy: 0.2720 - loss: 2.2516\n",
      "\u001b[1m 223/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 680us/step - accuracy: 0.2948 - loss: 2.2242\n",
      "\u001b[1m 292/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 692us/step - accuracy: 0.3084 - loss: 2.2017\n",
      "\u001b[1m 364/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 693us/step - accuracy: 0.3191 - loss: 2.1796\n",
      "\u001b[1m 438/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.3278 - loss: 2.1580\n",
      "\u001b[1m 507/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.3347 - loss: 2.1394\n",
      "\u001b[1m 578/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.3408 - loss: 2.1216\n",
      "\u001b[1m 655/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.3464 - loss: 2.1035\n",
      "\u001b[1m 734/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.3515 - loss: 2.0859\n",
      "\u001b[1m 810/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 685us/step - accuracy: 0.3558 - loss: 2.0701\n",
      "\u001b[1m 880/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.3593 - loss: 2.0563\n",
      "\u001b[1m 947/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.3623 - loss: 2.0438\n",
      "\u001b[1m1014/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.3652 - loss: 2.0316\n",
      "\u001b[1m1080/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.3679 - loss: 2.0202\n",
      "\u001b[1m1148/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.3705 - loss: 2.0089\n",
      "\u001b[1m1219/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.3729 - loss: 1.9976\n",
      "\u001b[1m1293/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.3753 - loss: 1.9864\n",
      "\u001b[1m1368/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.3775 - loss: 1.9755\n",
      "\u001b[1m1440/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.3796 - loss: 1.9655\n",
      "\u001b[1m1494/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.3810 - loss: 1.9583\n",
      "\u001b[1m1555/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 713us/step - accuracy: 0.3825 - loss: 1.9504\n",
      "\u001b[1m1629/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.3842 - loss: 1.9411\n",
      "\u001b[1m1704/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 709us/step - accuracy: 0.3859 - loss: 1.9322\n",
      "\u001b[1m1773/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 710us/step - accuracy: 0.3874 - loss: 1.9242\n",
      "\u001b[1m1840/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.3887 - loss: 1.9168\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 715us/step - accuracy: 0.3895 - loss: 1.9129\n",
      "\n",
      "Epoch 2/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 1.1715\n",
      "\u001b[1m  73/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 697us/step - accuracy: 0.4391 - loss: 1.5010\n",
      "\u001b[1m 151/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 670us/step - accuracy: 0.4454 - loss: 1.4956\n",
      "\u001b[1m 230/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 658us/step - accuracy: 0.4483 - loss: 1.4927\n",
      "\u001b[1m 306/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 659us/step - accuracy: 0.4492 - loss: 1.4915\n",
      "\u001b[1m 377/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.4503 - loss: 1.4893\n",
      "\u001b[1m 446/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.4514 - loss: 1.4874\n",
      "\u001b[1m 514/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.4524 - loss: 1.4856\n",
      "\u001b[1m 577/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.4531 - loss: 1.4841\n",
      "\u001b[1m 647/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.4537 - loss: 1.4826\n",
      "\u001b[1m 712/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.4539 - loss: 1.4818\n",
      "\u001b[1m 786/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.4543 - loss: 1.4809\n",
      "\u001b[1m 860/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 703us/step - accuracy: 0.4547 - loss: 1.4798\n",
      "\u001b[1m 911/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 719us/step - accuracy: 0.4550 - loss: 1.4790\n",
      "\u001b[1m 969/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.4554 - loss: 1.4780\n",
      "\u001b[1m1018/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.4558 - loss: 1.4771\n",
      "\u001b[1m1073/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.4563 - loss: 1.4762\n",
      "\u001b[1m1139/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.4568 - loss: 1.4752\n",
      "\u001b[1m1186/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.4572 - loss: 1.4744\n",
      "\u001b[1m1250/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.4578 - loss: 1.4733\n",
      "\u001b[1m1324/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.4585 - loss: 1.4720\n",
      "\u001b[1m1386/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.4592 - loss: 1.4709\n",
      "\u001b[1m1458/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.4600 - loss: 1.4695\n",
      "\u001b[1m1533/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.4608 - loss: 1.4681\n",
      "\u001b[1m1577/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.4613 - loss: 1.4672\n",
      "\u001b[1m1646/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.4619 - loss: 1.4659\n",
      "\u001b[1m1722/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.4627 - loss: 1.4645\n",
      "\u001b[1m1800/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.4634 - loss: 1.4630\n",
      "\u001b[1m1868/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.4641 - loss: 1.4616\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.4641 - loss: 1.4615\n",
      "\n",
      "Epoch 3/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.5312 - loss: 1.3447\n",
      "\u001b[1m  68/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 753us/step - accuracy: 0.5026 - loss: 1.3609\n",
      "\u001b[1m 147/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 689us/step - accuracy: 0.5046 - loss: 1.3630\n",
      "\u001b[1m 228/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 664us/step - accuracy: 0.5080 - loss: 1.3602\n",
      "\u001b[1m 310/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 651us/step - accuracy: 0.5100 - loss: 1.3582\n",
      "\u001b[1m 392/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.5111 - loss: 1.3563\n",
      "\u001b[1m 475/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.5122 - loss: 1.3547\n",
      "\u001b[1m 543/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.5129 - loss: 1.3535\n",
      "\u001b[1m 622/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.5135 - loss: 1.3523\n",
      "\u001b[1m 705/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.5143 - loss: 1.3509\n",
      "\u001b[1m 788/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.5150 - loss: 1.3494\n",
      "\u001b[1m 871/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.5156 - loss: 1.3480\n",
      "\u001b[1m 954/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.5161 - loss: 1.3464\n",
      "\u001b[1m1038/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.5167 - loss: 1.3447\n",
      "\u001b[1m1121/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.5173 - loss: 1.3430\n",
      "\u001b[1m1204/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.5178 - loss: 1.3412\n",
      "\u001b[1m1288/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.5184 - loss: 1.3395\n",
      "\u001b[1m1371/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.5189 - loss: 1.3379\n",
      "\u001b[1m1448/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.5192 - loss: 1.3365\n",
      "\u001b[1m1529/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.5196 - loss: 1.3351\n",
      "\u001b[1m1609/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 626us/step - accuracy: 0.5200 - loss: 1.3338\n",
      "\u001b[1m1691/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.5204 - loss: 1.3324\n",
      "\u001b[1m1774/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 624us/step - accuracy: 0.5207 - loss: 1.3311\n",
      "\u001b[1m1857/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 623us/step - accuracy: 0.5211 - loss: 1.3298\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627us/step - accuracy: 0.5212 - loss: 1.3295\n",
      "\n",
      "Epoch 4/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.5312 - loss: 1.2875\n",
      "\u001b[1m  73/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 696us/step - accuracy: 0.5379 - loss: 1.2840\n",
      "\u001b[1m 154/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 656us/step - accuracy: 0.5336 - loss: 1.2894\n",
      "\u001b[1m 236/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 642us/step - accuracy: 0.5334 - loss: 1.2867\n",
      "\u001b[1m 306/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 661us/step - accuracy: 0.5337 - loss: 1.2860\n",
      "\u001b[1m 385/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.5345 - loss: 1.2844\n",
      "\u001b[1m 467/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.5347 - loss: 1.2841\n",
      "\u001b[1m 549/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.5350 - loss: 1.2839\n",
      "\u001b[1m 631/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.5354 - loss: 1.2833\n",
      "\u001b[1m 710/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.5361 - loss: 1.2823\n",
      "\u001b[1m 792/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.5369 - loss: 1.2809\n",
      "\u001b[1m 872/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.5376 - loss: 1.2798\n",
      "\u001b[1m 943/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.5381 - loss: 1.2789\n",
      "\u001b[1m1024/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.5388 - loss: 1.2778\n",
      "\u001b[1m1101/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.5395 - loss: 1.2766\n",
      "\u001b[1m1181/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.5402 - loss: 1.2756\n",
      "\u001b[1m1262/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.5408 - loss: 1.2744\n",
      "\u001b[1m1341/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.5414 - loss: 1.2733\n",
      "\u001b[1m1424/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.5420 - loss: 1.2720\n",
      "\u001b[1m1506/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.5426 - loss: 1.2708\n",
      "\u001b[1m1589/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 634us/step - accuracy: 0.5432 - loss: 1.2696\n",
      "\u001b[1m1670/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 633us/step - accuracy: 0.5437 - loss: 1.2685\n",
      "\u001b[1m1753/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.5442 - loss: 1.2674\n",
      "\u001b[1m1836/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.5447 - loss: 1.2663\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634us/step - accuracy: 0.5449 - loss: 1.2658\n",
      "\n",
      "Epoch 5/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 8ms/step - accuracy: 0.5312 - loss: 1.1435\n",
      "\u001b[1m  63/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 816us/step - accuracy: 0.5568 - loss: 1.1899\n",
      "\u001b[1m 141/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 722us/step - accuracy: 0.5608 - loss: 1.1951\n",
      "\u001b[1m 219/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 694us/step - accuracy: 0.5602 - loss: 1.1990\n",
      "\u001b[1m 300/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 674us/step - accuracy: 0.5611 - loss: 1.1983\n",
      "\u001b[1m 381/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.5630 - loss: 1.1968\n",
      "\u001b[1m 462/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.5639 - loss: 1.1969\n",
      "\u001b[1m 542/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.5648 - loss: 1.1965\n",
      "\u001b[1m 624/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.5656 - loss: 1.1962\n",
      "\u001b[1m 676/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.5660 - loss: 1.1962\n",
      "\u001b[1m 745/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.5665 - loss: 1.1959\n",
      "\u001b[1m 817/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.5671 - loss: 1.1952\n",
      "\u001b[1m 894/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.5676 - loss: 1.1946\n",
      "\u001b[1m 975/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.5680 - loss: 1.1940\n",
      "\u001b[1m1056/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.5684 - loss: 1.1933\n",
      "\u001b[1m1139/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.5687 - loss: 1.1927\n",
      "\u001b[1m1222/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.5689 - loss: 1.1922\n",
      "\u001b[1m1305/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.5690 - loss: 1.1917\n",
      "\u001b[1m1388/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.5691 - loss: 1.1913\n",
      "\u001b[1m1460/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.5692 - loss: 1.1909\n",
      "\u001b[1m1536/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.5693 - loss: 1.1904\n",
      "\u001b[1m1619/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.5695 - loss: 1.1899\n",
      "\u001b[1m1702/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.5696 - loss: 1.1894\n",
      "\u001b[1m1786/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.5698 - loss: 1.1887\n",
      "\u001b[1m1870/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.5700 - loss: 1.1881\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650us/step - accuracy: 0.5700 - loss: 1.1881\n",
      "\n",
      "313/313 - 0s - 627us/step - accuracy: 0.9163 - loss: 0.5367                    \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step             \n",
      "\u001b[1m141/313\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 358us/step   \n",
      "\u001b[1m294/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 343us/step  \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step  \n",
      "\n",
      " 33%|███▎      | 1/3 [00:19<00:25, 12.56s/trial, best loss: 0.4684818983078003]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/06 14:00:00 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|##########| 1/1 [00:00<00:00, 4644.85it/s]\n",
      "Downloading artifacts: 100%|##########| 1/1 [00:00<00:00, 1530.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step        \n",
      "\n",
      "🏃 View run zealous-worm-828 at: http://mlflow-server:8888/#/experiments/791152268774684723/runs/690f39140d4a47138de8a25145c4620b\n",
      "\n",
      "🧪 View experiment at: http://mlflow-server:8888/#/experiments/791152268774684723\n",
      "\n",
      "(60000, 28, 28)                                                                \n",
      " 67%|██████▋   | 2/3 [00:20<00:09,  9.71s/trial, best loss: 0.4684818983078003]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:38\u001b[0m 181ms/step - accuracy: 0.0625 - loss: 2.3897\n",
      "\u001b[1m  52/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 983us/step - accuracy: 0.5040 - loss: 1.6303  \n",
      "\u001b[1m 108/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.6144 - loss: 1.3265\n",
      "\u001b[1m 168/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 905us/step - accuracy: 0.6701 - loss: 1.1491\n",
      "\u001b[1m 229/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 883us/step - accuracy: 0.7049 - loss: 1.0323\n",
      "\u001b[1m 288/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 876us/step - accuracy: 0.7285 - loss: 0.9516\n",
      "\u001b[1m 349/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 868us/step - accuracy: 0.7466 - loss: 0.8887\n",
      "\u001b[1m 410/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.7607 - loss: 0.8393\n",
      "\u001b[1m 469/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.7720 - loss: 0.7993\n",
      "\u001b[1m 529/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 858us/step - accuracy: 0.7815 - loss: 0.7649\n",
      "\u001b[1m 590/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 854us/step - accuracy: 0.7898 - loss: 0.7349\n",
      "\u001b[1m 652/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 850us/step - accuracy: 0.7972 - loss: 0.7084\n",
      "\u001b[1m 714/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.8037 - loss: 0.6850\n",
      "\u001b[1m 776/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8095 - loss: 0.6641\n",
      "\u001b[1m 838/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8147 - loss: 0.6455\n",
      "\u001b[1m 899/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.8193 - loss: 0.6289\n",
      "\u001b[1m 960/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8236 - loss: 0.6138\n",
      "\u001b[1m1020/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.8274 - loss: 0.6000\n",
      "\u001b[1m1077/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8308 - loss: 0.5879\n",
      "\u001b[1m1120/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.8332 - loss: 0.5794\n",
      "\u001b[1m1173/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.8360 - loss: 0.5695\n",
      "\u001b[1m1224/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.8384 - loss: 0.5604\n",
      "\u001b[1m1275/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.8408 - loss: 0.5519\n",
      "\u001b[1m1327/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8431 - loss: 0.5438\n",
      "\u001b[1m1380/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.8453 - loss: 0.5358\n",
      "\u001b[1m1436/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.8475 - loss: 0.5279\n",
      "\u001b[1m1494/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.8497 - loss: 0.5200\n",
      "\u001b[1m1550/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.8517 - loss: 0.5129\n",
      "\u001b[1m1600/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.8534 - loss: 0.5068\n",
      "\u001b[1m1653/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.8551 - loss: 0.5006\n",
      "\u001b[1m1707/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.8568 - loss: 0.4945\n",
      "\u001b[1m1757/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.8583 - loss: 0.4892\n",
      "\u001b[1m1808/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.8598 - loss: 0.4839\n",
      "\u001b[1m1860/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.8612 - loss: 0.4788\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 898us/step - accuracy: 0.8617 - loss: 0.4772\n",
      "\n",
      "Epoch 2/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.1028\n",
      "\u001b[1m  48/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9451 - loss: 0.1842  \n",
      "\u001b[1m  90/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9468 - loss: 0.1832\n",
      "\u001b[1m 146/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9481 - loss: 0.1805\n",
      "\u001b[1m 197/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9490 - loss: 0.1787\n",
      "\u001b[1m 249/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9494 - loss: 0.1781\n",
      "\u001b[1m 297/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9495 - loss: 0.1781\n",
      "\u001b[1m 333/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9496 - loss: 0.1777\n",
      "\u001b[1m 377/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9498 - loss: 0.1772\n",
      "\u001b[1m 389/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9499 - loss: 0.1771\n",
      "\u001b[1m 433/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9500 - loss: 0.1767\n",
      "\u001b[1m 480/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9503 - loss: 0.1759\n",
      "\u001b[1m 531/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9506 - loss: 0.1750\n",
      "\u001b[1m 584/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9509 - loss: 0.1741\n",
      "\u001b[1m 640/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9511 - loss: 0.1731\n",
      "\u001b[1m 697/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9514 - loss: 0.1720\n",
      "\u001b[1m 753/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9517 - loss: 0.1710\n",
      "\u001b[1m 813/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9519 - loss: 0.1701\n",
      "\u001b[1m 873/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9521 - loss: 0.1693\n",
      "\u001b[1m 932/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9523 - loss: 0.1686\n",
      "\u001b[1m 992/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9525 - loss: 0.1679\n",
      "\u001b[1m1048/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9527 - loss: 0.1672\n",
      "\u001b[1m1107/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9528 - loss: 0.1666\n",
      "\u001b[1m1159/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9529 - loss: 0.1661\n",
      "\u001b[1m1216/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 998us/step - accuracy: 0.9531 - loss: 0.1656\n",
      "\u001b[1m1271/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 994us/step - accuracy: 0.9532 - loss: 0.1651\n",
      "\u001b[1m1328/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.9533 - loss: 0.1647\n",
      "\u001b[1m1389/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 982us/step - accuracy: 0.9534 - loss: 0.1642\n",
      "\u001b[1m1450/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.9535 - loss: 0.1638\n",
      "\u001b[1m1512/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 969us/step - accuracy: 0.9536 - loss: 0.1634\n",
      "\u001b[1m1573/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 963us/step - accuracy: 0.9537 - loss: 0.1630\n",
      "\u001b[1m1634/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.9538 - loss: 0.1626\n",
      "\u001b[1m1696/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.9539 - loss: 0.1622\n",
      "\u001b[1m1757/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 949us/step - accuracy: 0.9539 - loss: 0.1618\n",
      "\u001b[1m1818/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.9540 - loss: 0.1614\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 945us/step - accuracy: 0.9541 - loss: 0.1610\n",
      "\n",
      "Epoch 3/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.9062 - loss: 0.2894\n",
      "\u001b[1m  59/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9729 - loss: 0.1063\n",
      "\u001b[1m 120/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 848us/step - accuracy: 0.9700 - loss: 0.1058\n",
      "\u001b[1m 180/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 844us/step - accuracy: 0.9689 - loss: 0.1049\n",
      "\u001b[1m 241/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.9678 - loss: 0.1064\n",
      "\u001b[1m 302/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 836us/step - accuracy: 0.9672 - loss: 0.1068\n",
      "\u001b[1m 364/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 833us/step - accuracy: 0.9668 - loss: 0.1076\n",
      "\u001b[1m 426/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 831us/step - accuracy: 0.9664 - loss: 0.1088\n",
      "\u001b[1m 487/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 830us/step - accuracy: 0.9661 - loss: 0.1098\n",
      "\u001b[1m 540/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.9659 - loss: 0.1106\n",
      "\u001b[1m 599/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 843us/step - accuracy: 0.9657 - loss: 0.1113\n",
      "\u001b[1m 660/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.9656 - loss: 0.1120\n",
      "\u001b[1m 713/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.9655 - loss: 0.1125\n",
      "\u001b[1m 774/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.9655 - loss: 0.1131\n",
      "\u001b[1m 835/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.9654 - loss: 0.1136\n",
      "\u001b[1m 897/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9654 - loss: 0.1140\n",
      "\u001b[1m 958/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9654 - loss: 0.1144\n",
      "\u001b[1m1020/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9654 - loss: 0.1147\n",
      "\u001b[1m1081/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 840us/step - accuracy: 0.9654 - loss: 0.1150\n",
      "\u001b[1m1142/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9654 - loss: 0.1152\n",
      "\u001b[1m1204/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9655 - loss: 0.1153\n",
      "\u001b[1m1258/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.9655 - loss: 0.1154\n",
      "\u001b[1m1320/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.9655 - loss: 0.1156\n",
      "\u001b[1m1382/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9655 - loss: 0.1158\n",
      "\u001b[1m1444/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.9655 - loss: 0.1159\n",
      "\u001b[1m1505/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.9655 - loss: 0.1161\n",
      "\u001b[1m1566/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.9655 - loss: 0.1162\n",
      "\u001b[1m1628/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.9655 - loss: 0.1164\n",
      "\u001b[1m1690/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.9656 - loss: 0.1164\n",
      "\u001b[1m1752/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.9656 - loss: 0.1165\n",
      "\u001b[1m1795/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.9656 - loss: 0.1165\n",
      "\u001b[1m1846/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.9656 - loss: 0.1165\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 850us/step - accuracy: 0.9656 - loss: 0.1166\n",
      "\n",
      "Epoch 4/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9688 - loss: 0.0651\n",
      "\u001b[1m  52/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 982us/step - accuracy: 0.9765 - loss: 0.0851\n",
      "\u001b[1m 109/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 930us/step - accuracy: 0.9769 - loss: 0.0840\n",
      "\u001b[1m 168/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.9763 - loss: 0.0861\n",
      "\u001b[1m 228/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 887us/step - accuracy: 0.9758 - loss: 0.0885\n",
      "\u001b[1m 289/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 874us/step - accuracy: 0.9754 - loss: 0.0901\n",
      "\u001b[1m 351/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 864us/step - accuracy: 0.9749 - loss: 0.0918\n",
      "\u001b[1m 381/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 0.9747 - loss: 0.0923\n",
      "\u001b[1m 437/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 924us/step - accuracy: 0.9745 - loss: 0.0929\n",
      "\u001b[1m 494/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.9742 - loss: 0.0935\n",
      "\u001b[1m 551/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 915us/step - accuracy: 0.9740 - loss: 0.0940\n",
      "\u001b[1m 610/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.9737 - loss: 0.0945\n",
      "\u001b[1m 670/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 903us/step - accuracy: 0.9735 - loss: 0.0950\n",
      "\u001b[1m 731/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 897us/step - accuracy: 0.9733 - loss: 0.0954\n",
      "\u001b[1m 791/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 893us/step - accuracy: 0.9731 - loss: 0.0958\n",
      "\u001b[1m 853/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9729 - loss: 0.0962\n",
      "\u001b[1m 914/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9728 - loss: 0.0966\n",
      "\u001b[1m 976/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.9726 - loss: 0.0968\n",
      "\u001b[1m1037/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9725 - loss: 0.0971\n",
      "\u001b[1m1086/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 883us/step - accuracy: 0.9724 - loss: 0.0972\n",
      "\u001b[1m1141/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9724 - loss: 0.0974\n",
      "\u001b[1m1199/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9723 - loss: 0.0976\n",
      "\u001b[1m1259/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.9722 - loss: 0.0977\n",
      "\u001b[1m1318/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9722 - loss: 0.0979\n",
      "\u001b[1m1379/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.9721 - loss: 0.0980\n",
      "\u001b[1m1439/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9720 - loss: 0.0982\n",
      "\u001b[1m1499/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.9720 - loss: 0.0983\n",
      "\u001b[1m1560/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9719 - loss: 0.0984\n",
      "\u001b[1m1622/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9718 - loss: 0.0985\n",
      "\u001b[1m1683/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.9718 - loss: 0.0986\n",
      "\u001b[1m1744/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.9717 - loss: 0.0987\n",
      "\u001b[1m1805/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9717 - loss: 0.0988\n",
      "\u001b[1m1864/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 866us/step - accuracy: 0.9716 - loss: 0.0989\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 869us/step - accuracy: 0.9716 - loss: 0.0989\n",
      "\n",
      "Epoch 5/5                                                                      \n",
      "\n",
      "\u001b[1m   1/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 9ms/step - accuracy: 0.9688 - loss: 0.0986\n",
      "\u001b[1m  46/1875\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9800 - loss: 0.0849 \n",
      "\u001b[1m 100/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9772 - loss: 0.0902\n",
      "\u001b[1m 159/1875\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 957us/step - accuracy: 0.9753 - loss: 0.0940\n",
      "\u001b[1m 219/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 926us/step - accuracy: 0.9745 - loss: 0.0945\n",
      "\u001b[1m 279/1875\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 909us/step - accuracy: 0.9743 - loss: 0.0944\n",
      "\u001b[1m 330/1875\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.9741 - loss: 0.0944\n",
      "\u001b[1m 377/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 940us/step - accuracy: 0.9740 - loss: 0.0944\n",
      "\u001b[1m 432/1875\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 938us/step - accuracy: 0.9740 - loss: 0.0942\n",
      "\u001b[1m 491/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 928us/step - accuracy: 0.9739 - loss: 0.0941\n",
      "\u001b[1m 551/1875\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.9738 - loss: 0.0942\n",
      "\u001b[1m 611/1875\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.9737 - loss: 0.0943\n",
      "\u001b[1m 673/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 902us/step - accuracy: 0.9736 - loss: 0.0943\n",
      "\u001b[1m 732/1875\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 898us/step - accuracy: 0.9736 - loss: 0.0943\n",
      "\u001b[1m 794/1875\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9735 - loss: 0.0944\n",
      "\u001b[1m 855/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 887us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m 915/1875\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m 976/1875\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1038/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1100/1875\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1161/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1191/1875\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1248/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1306/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9734 - loss: 0.0944\n",
      "\u001b[1m1362/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9734 - loss: 0.0943\n",
      "\u001b[1m1421/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9734 - loss: 0.0943\n",
      "\u001b[1m1482/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9734 - loss: 0.0942\n",
      "\u001b[1m1542/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.9734 - loss: 0.0942\n",
      "\u001b[1m1595/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.9734 - loss: 0.0942\n",
      "\u001b[1m1645/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9735 - loss: 0.0941\n",
      "\u001b[1m1702/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.9735 - loss: 0.0940\n",
      "\u001b[1m1762/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9735 - loss: 0.0940\n",
      "\u001b[1m1815/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.9735 - loss: 0.0939\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.9735 - loss: 0.0939\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 892us/step - accuracy: 0.9735 - loss: 0.0939\n",
      "\n",
      "313/313 - 0s - 630us/step - accuracy: 0.9751 - loss: 0.0920                    \n",
      "\n",
      "\u001b[1m  1/313\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 14ms/step             \n",
      "\u001b[1m138/313\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 367us/step   \n",
      "\u001b[1m287/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 352us/step  \n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step  \n",
      "\n",
      " 67%|██████▋   | 2/3 [00:29<00:09,  9.71s/trial, best loss: 0.4684818983078003]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/06 14:00:10 INFO mlflow.pyfunc: Validating input example against model signature\n",
      "\n",
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|##########| 1/1 [00:00<00:00, 5526.09it/s]\n",
      "Downloading artifacts: 100%|##########| 1/1 [00:00<00:00, 1778.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step        \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step        \n",
      "\n",
      "🏃 View run silent-doe-583 at: http://mlflow-server:8888/#/experiments/791152268774684723/runs/7162292e2b3b4200bd90b4924c0797d9\n",
      "\n",
      "🧪 View experiment at: http://mlflow-server:8888/#/experiments/791152268774684723\n",
      "\n",
      "100%|██████████| 3/3 [00:30<00:00, 10.02s/trial, best loss: 0.09196963906288147]\n",
      "🏃 View run handsome-penguin-552 at: http://mlflow-server:8888/#/experiments/791152268774684723/runs/c06a512468274d40a587ca625356c7ac\n",
      "🧪 View experiment at: http://mlflow-server:8888/#/experiments/791152268774684723\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run :\n",
    "   args_min = fmin(\n",
    "      fn=train_with_hyperopt,\n",
    "      space=search_params_space,\n",
    "      algo = algo,\n",
    "      max_evals=3,\n",
    "      trials=spark_trails\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Generic model flavours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs': 1,\n",
       " 'l1_activation': 0,\n",
       " 'l1_dropout': 0,\n",
       " 'l1_noNode': 2,\n",
       " 'optimizer': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 8/8 [00:00<00:00, 39.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-2.07438412e+01, -2.68373718e+01, -1.43511953e+01,\n",
       "        -1.31022997e+01, -3.17486744e+01, -2.07132778e+01,\n",
       "        -3.98017273e+01,  2.21492028e+00, -2.11091900e+01,\n",
       "        -1.50475225e+01],\n",
       "       [-2.63567982e+01, -2.46835442e+01, -7.14326620e+00,\n",
       "        -1.94634762e+01, -5.03084259e+01, -1.89139347e+01,\n",
       "        -2.53687305e+01, -5.32230530e+01, -2.13532505e+01,\n",
       "        -5.10502281e+01],\n",
       "       [-1.51637983e+01, -1.50215961e-02, -8.67891026e+00,\n",
       "        -1.12270765e+01, -9.26923084e+00, -1.25367041e+01,\n",
       "        -1.12341452e+01, -7.03493595e+00, -7.61905003e+00,\n",
       "        -1.36733227e+01],\n",
       "       [-1.90891540e+00, -2.66366730e+01, -1.16486149e+01,\n",
       "        -1.90971699e+01, -1.75488415e+01, -1.45749159e+01,\n",
       "        -1.19489565e+01, -1.53349733e+01, -2.04615974e+01,\n",
       "        -1.39360886e+01],\n",
       "       [-1.34536943e+01, -2.51595230e+01, -1.31930084e+01,\n",
       "        -1.71255360e+01, -5.45159817e-01, -1.49733658e+01,\n",
       "        -1.33382006e+01, -9.11560154e+00, -1.51723700e+01,\n",
       "        -7.29219484e+00],\n",
       "       [-1.78062897e+01,  4.17065501e-01, -1.16406069e+01,\n",
       "        -1.32993088e+01, -9.25543880e+00, -1.58792543e+01,\n",
       "        -1.49218340e+01, -6.85378599e+00, -9.24650002e+00,\n",
       "        -1.36950283e+01],\n",
       "       [-2.67554760e+01, -2.12801476e+01, -2.02380695e+01,\n",
       "        -2.21718826e+01, -2.28284806e-01, -1.61344318e+01,\n",
       "        -1.83655605e+01, -1.09849672e+01, -1.49431906e+01,\n",
       "        -1.13289928e+01],\n",
       "       [-2.48465538e+01, -1.71951370e+01, -1.57411509e+01,\n",
       "        -6.47369385e+00, -9.88477325e+00, -1.24619598e+01,\n",
       "        -3.06162090e+01, -1.04710703e+01, -1.33926392e+01,\n",
       "        -1.52919447e+00],\n",
       "       [-3.71385727e+01, -3.89885941e+01, -2.82610111e+01,\n",
       "        -3.94854660e+01, -3.01199799e+01, -1.27061853e+01,\n",
       "        -1.58153744e+01, -3.86653442e+01, -2.60789680e+01,\n",
       "        -2.71468792e+01],\n",
       "       [-3.21412277e+01, -3.30075874e+01, -2.98019409e+01,\n",
       "        -2.38561726e+01, -9.49698067e+00, -2.31771011e+01,\n",
       "        -3.56270752e+01, -1.24774141e+01, -1.75199165e+01,\n",
       "        -2.72029614e+00]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "# Get the actual run ID where model was logged\n",
    "best_trial = spark_trails.best_trial\n",
    "model_run_id = best_trial['result']['run_id']\n",
    "\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(f'runs:/{model_run_id}/custom_tf')\n",
    "\n",
    "# Predict on a Pandas DataFrame.\n",
    "import pandas as pd\n",
    "result = loaded_model.predict(x_test[:10])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
